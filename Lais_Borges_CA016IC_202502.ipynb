{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwM_in1WXc79"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Lais Aparecida Borges\n",
        "# Projeto: Corretor de Redações para o ENEM com LLM\n",
        "#\n",
        "# Disciplina: CA016IC - Tópicos em Inteligência Computacional\n",
        "#\n",
        "# Problema\n",
        "#\n",
        "# O ENEM, principal porta de entrada para o ensino superior no Brasil, avalia os\n",
        "# candidatos em diversas competências. A qualidade e a adequação da redação\n",
        "# são fatores determinantes para o sucesso dos estudantes.\n",
        "# No entanto, o acesso a feedback personalizado e detalhado sobre redações pode\n",
        "# ser limitado, especialmente fora de cursos preparatórios.\n",
        "#\n",
        "# Objetivo\n",
        "#\n",
        "# Este projeto visa desenvolver um protótipo de corretor de redações para o ENEM\n",
        "# que integra a funcionalidade de Retrieval-Augmented Generation (RAG) com um\n",
        "# LLM finetunado para o contexto da língua portuguesa e o exame. O sistema\n",
        "# receberá um texto de redação e o tema proposto, e utilizará um banco de dados\n",
        "# vetorial contendo comentários de redações anteriores para gerar um feedback\n",
        "# detalhado e contextualizado.\n",
        "#\n",
        "# O foco principal é na aplicabilidade prática e na geração de feedback que\n",
        "# aborde os critérios de avaliação do ENEM, utilizando um LLM\n",
        "# (Qwen2.5-0.5B-PT-BR-Instruct) com adaptações via LoRA e um modelo de embedding\n",
        "# otimizado para português (paraphrase-multilingual-MiniLM-L12-v2).\n",
        "#\n",
        "# Escopo e Limitações\n",
        "#\n",
        "# - O corpus de redações utilizado é proveniente do repositório uol-redacoes-xml.\n",
        "# - A tokenização é realizada pelo tokenizer do modelo Qwen2.5.\n",
        "# - O modelo base é o Qwen2.5-0.5B-PT-BR-Instruct, finetunado com LoRA.\n",
        "# - O RAG é implementado utilizando ChromaDB e Sentence Transformers.\n",
        "# - A avaliação de saída é realizada com métricas ROUGE, BERTScore e BLEU.\n",
        "# - O feedback gerado é um protótipo e pode necessitar de refinamentos para\n",
        "#   cobrir todas as nuances de cada competência do ENEM.\n",
        "#\n",
        "# Referências\n",
        "#\n",
        "# uol-redacoes-xml: Repositório de dados de redações.\n",
        "# Disponível em: https://github.com/gpassero/uol-redacoes-xml\n",
        "#\n",
        "# Hugging Face Transformers, PEFT, Datasets, Evaluate, Sentence Transformers.\n",
        "# ============================================================================="
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 1: INSTALAÇÃO DE BIBLIOTECAS E PACOTES\n",
        "# =============================================================================\n",
        "\n",
        "# Instalação do pacote proveniente do repositório que contém um banco de\n",
        "# redações em formato XML, com dados como o tema da redação, o texto produzido,\n",
        "# o texto corrigido, os comentários dos avaliadores, entre outras informações.\n",
        "!pip install git+https://github.com/gpassero/uol-redacoes-xml.git\n",
        "\n",
        "# Instalação das bibliotecas necessárias\n",
        "!pip install -q transformers datasets accelerate peft bitsandbytes trl evaluate chromadb sentence-transformers rouge_score bert_score"
      ],
      "metadata": {
        "id": "etKZxVaza84j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a04877-2172-4b8f-c77b-138daa6ecaf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/gpassero/uol-redacoes-xml.git\n",
            "  Cloning https://github.com/gpassero/uol-redacoes-xml.git to /tmp/pip-req-build-7ce2on77\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/gpassero/uol-redacoes-xml.git /tmp/pip-req-build-7ce2on77\n",
            "  Resolved https://github.com/gpassero/uol-redacoes-xml.git to commit 94b74fc91c4e7a6b582ebc3708aa0dca2ba12ca6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: uol_redacoes_xml\n",
            "  Building wheel for uol_redacoes_xml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uol_redacoes_xml: filename=uol_redacoes_xml-0.2-py3-none-any.whl size=2978835 sha256=48f4b4be65d67531391c5f863e3ebcc73438c21c62c8f38f58e85271a3d6d387\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xk782ri6/wheels/c1/e3/ee/70fe667b172b519fa5f401241e6af9b31ab33b05cf715341e5\n",
            "Successfully built uol_redacoes_xml\n",
            "Installing collected packages: uol_redacoes_xml\n",
            "Successfully installed uol_redacoes_xml-0.2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 2: IMPORTAÇÕES NECESSÁRIAS\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import chromadb\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import Dataset\n",
        "from evaluate import load\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "from evaluate import load\n",
        "from bert_score import score\n",
        "\n",
        "# Bibliotecas necessárias para a base de dados\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "import uol_redacoes_xml"
      ],
      "metadata": {
        "id": "R_rejxPTbs5Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b792218-2856-41c7-c401-b7e53967ed50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 3: CRIAÇÃO DO DATAFRAME\n",
        "# =============================================================================\n",
        "\n",
        "# Para evitar erros com o pacote de redações, as informações julgadas\n",
        "# relevantes para o feedback (tema, redação e comentários) são passadas para um\n",
        "# DataFrame, que é salvo localmente.\n",
        "\n",
        "# Carregamento das redações\n",
        "essays = uol_redacoes_xml.load()\n",
        "\n",
        "data = []\n",
        "\n",
        "for essay in essays:\n",
        "  # Limpeza de tags HTML/XML nos comentários\n",
        "  essay.comments = essay.comments.replace('<comments>', '')\n",
        "  essay.comments = essay.comments.replace('</comments>', '')\n",
        "\n",
        "  data.append({\n",
        "      'THEME': essay.prompt.title,\n",
        "      'ESSAY': essay.text,\n",
        "      'COMMENTS': essay.comments\n",
        "  })\n",
        "\n",
        "filename = 'Essays.csv'\n",
        "df_essays = pd.DataFrame(data)\n",
        "df_essays.drop_duplicates(subset='ESSAY', inplace=True)\n",
        "df_essays.dropna(inplace=True)\n",
        "df_essays.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "Hho_ncW6b5zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc34dc2-e717-409d-d12f-03a4be302105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:uol_redacoes_xml:UOL essays load warnings: \n",
            "WARNING:uol_redacoes_xml:No text  ->  3\n",
            "WARNING:uol_redacoes_xml:Final score != from sum of criteria score  ->  45\n",
            "WARNING:uol_redacoes_xml:Not 5 criteria  ->  7\n",
            "WARNING:uol_redacoes_xml:Total warnings: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 4: CARREGAMENTO DO MODELO PRÉ-TREINADO\n",
        "# =============================================================================\n",
        "model_id = \"amadeusai/AV-FI-Qwen2.5-0.5B-PT-BR-Instruct\" # Especializado na língua portuguesa\n",
        "\n",
        "# Tokenização do modelo\n",
        "tok = AutoTokenizer.from_pretrained(model_id)\n",
        "if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    dtype=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model"
      ],
      "metadata": {
        "id": "AvP8LZgPgC69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880,
          "referenced_widgets": [
            "3844e16c93ca40c7b313661219906268",
            "8ac0878677b14b62b9b72b804c159a94",
            "eb467d0649e34f79875cf00ea88e6c39",
            "da716e3cbe0a4f519c82165f4740a044",
            "30e9a5aef6814258b6f15a78d13628df",
            "6c0cefa369c34207aa2e8dc9759be466",
            "dc818206fe6d4825a338d873077734b6",
            "8ce7686f5b754b4a885e854a6d3e6aa8",
            "4740cb8b4f174ae0b8144ef0622d3d78",
            "50f0da4fa1f64f24b2795c6f0efee7fc",
            "f6f5fb8ea1dd4359b07c75e027459a74",
            "43024800f3d84a35ae83795cafd80b29",
            "098334d299bf4a9f938de8ddf810daee",
            "2d0fa8a690d448afb76398829385035c",
            "65eb12e587a749ba8e229c2fda53f6b9",
            "1740d0c38ddc49cb8748f2a675c39514",
            "6abe44de8e5d42eda7a36ea34b753f23",
            "145567261d0143dab730aa173a1d7883",
            "a4ae59065a63408dadff99f567e667bc",
            "19c7c2ddd2784dc4ace8d840982cfb10",
            "68612a0cdacf4b2d92979fff7a9c6a9d",
            "058b69c2240f4c61a272e7f63cf62b7c",
            "0f4c21cbf58b447ebff30460612b5641",
            "d31d43f4a2f04892a8a7bd03df6569be",
            "aebac91b9bac456083b7a5215101f326",
            "c827999237f24d4dbc75c111424daa8e",
            "ed889fd1b2f341f9a692a64843cb3d4c",
            "a5e14ab5806a4849bf2f81bb303f0cf9",
            "cff3c44c639e4effb60398d1c3a31473",
            "3f90c4cc0283412e9aa38c7f83662b72",
            "b34f458c3ce04381b0cbcc29adc14ec9",
            "160cce9df81d455c9418f688947b62e9",
            "69493874fded423db0e987100e87e24b",
            "10319448172148dda980d1def0d2291c",
            "8c79e9ec326c44268465a662b20e9bf4",
            "53e859ac3f6a4abe969449bccdde209c",
            "e8041ed4b0cf4ce7b12ff56155a00af5",
            "cf06bb2b78c1434f9e5466c2c31e49df",
            "4f79a4bb8ac540f9b43ada2dbfa43b5d",
            "56c1caf66fce41359fadee667bfeb02c",
            "3e02ea0775ad4b7a9cb7e06d1c671307",
            "d598967856bb43b9a988c92ddc50206f",
            "9c6b16245c3f4be7bc6f4a9b713f4196",
            "33d153b63a0d4865bd06b54a93cf3f57",
            "d65d0288fb1e478197ff8b46dfc45362",
            "73acdb086dbb4431b3adafd7f312d7b2",
            "f9bb176c79e448a6a29c18b2bcebb213",
            "ca39406c6a7f48f2bea3047a01de1021",
            "13408f7d17f9405e85ef6f72514d97bf",
            "7d25ab96a1c24729ae6a800812b191a1",
            "3c0e1d7728414a0ea1ed8b64b230269e",
            "3dde1d408b8e4c548d60960c7097ea32",
            "21c50dc6308f442dac0776cc954510e8",
            "fd1a8f3ea2d04418a361b65509ba5db6",
            "fb4b03dfc34e408eb8f8997e69ab883d",
            "a88e95fa80b24b26bf6fa4c8e799ec71",
            "914255ede6e14aada4bcab89f5642be3",
            "1c2f6a8da1ea4f94832591ef921fdcf0",
            "af814e045df74c54ab3d9af77bb8712c",
            "42f51fa61e3549cd8a7efa80c1dff7c3",
            "431a071b837f4dd9a31a25188047f5d5",
            "9a54a718c4234aebbdcac6ba18b8a674",
            "2d29017644b04eccb1c84fd41c6f2d73",
            "b2fc2cc9f1514196b6fc5c890566652b",
            "a0aac49ac45b49a6a7bd04fbd7b0fd22",
            "a39417a2b6614de8b0455f7ec30fae5b",
            "baeb1404a8684546a198a1710e841848",
            "715b45e85d5d432c8b09cc82d0f5b897",
            "745f88c3c045480bbe4a1d5c8b6a264c",
            "8c2757b6376a4ae69e0695946cb83106",
            "f9ed3814ab364cb4aa687062579be132",
            "6cc05908195840b2a975943af477838a",
            "29855fec12ec49ba96cf5cfc6e2ebb54",
            "05a7869379f6428f91c26b839c4b91c2",
            "8bb32b53fc2249f5b5a1f03c2c1a6ce4",
            "aca9b170faae495eaa353b030111c874",
            "3cfa8559354e4b1ebef32481f82c1909",
            "7ac4aaf0b3644253ae638b7e390609f1",
            "c8dcafaddf9d4d0aa09618c304e26d09",
            "b622a012628a444090756b69c18c98d1",
            "4cd56549e3d74531b59daf76f4b79b1d",
            "27d3b6027e6e46bdb5201a18936f605d",
            "b43670e2fab343d1b30a1a8469a5fe59",
            "e7a7e6e3c7a2424895e515085d71522c",
            "9b501df6169c47a29b534f360b4d6646",
            "77ec3a1afd7c475abcc880325da3fc18",
            "ee09aba3b3be4f60baf29236d0d87982",
            "a280e66bf7114098806907793300acda",
            "8b840e4541134d0397af57019a7feb64",
            "1f9af8b29f0f4e72a2d5c0a7504ac523",
            "78fe65eab0624c5eb1cc56ab12fc0751",
            "9b62535eaeef43a291eb1509387695e9",
            "6e4a967370ec485eb46883212d63496f",
            "248bf366a7b74fdba0964f3545f0ae57",
            "e8836dd6b62741ca8f973530ec31adbf",
            "22bbcf7ae62c4f538ee9abf9bbaf1524",
            "42e2a8c5131e4ebdb570512e4a48743e",
            "2c49e052f94d464aa9f29d3ceb761c92",
            "78f04e77f7fd46f28801d4ae6b4ca305"
          ]
        },
        "outputId": "6acb9934-78e3-4321-b589-3fd96a051976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3844e16c93ca40c7b313661219906268"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43024800f3d84a35ae83795cafd80b29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f4c21cbf58b447ebff30460612b5641"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10319448172148dda980d1def0d2291c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d65d0288fb1e478197ff8b46dfc45362"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/499 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a88e95fa80b24b26bf6fa4c8e799ec71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/778 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "baeb1404a8684546a198a1710e841848"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ac4aaf0b3644253ae638b7e390609f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/246 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b840e4541134d0397af57019a7feb64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 5: CONFIGURAÇÃO DO LORA\n",
        "# =============================================================================\n",
        "lora_cfg = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_cfg)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HZdQR-2m3Wf",
        "outputId": "33a54c94-ed2d-4744-c395-92980877a6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Qwen2ForCausalLM(\n",
              "      (model): Qwen2Model(\n",
              "        (embed_tokens): Embedding(151936, 896)\n",
              "        (layers): ModuleList(\n",
              "          (0-23): 24 x Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2Attention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=896, out_features=896, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=896, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=128, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=128, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=896, out_features=896, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=896, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4864, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=896, out_features=4864, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=896, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4864, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4864, out_features=896, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4864, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=896, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "          )\n",
              "        )\n",
              "        (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (rotary_emb): Qwen2RotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 6: CARREGAMENTO DO MODELO DE EMBEDDINGS\n",
        "# =============================================================================\n",
        "# Carregamento do modelo de embedding capaz de compreender\n",
        "# a intenção e o contexto em português.\n",
        "embedding_model_id = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
        "embedding_model = SentenceTransformer(embedding_model_id)\n",
        "embedding_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "7296ecc159d24531964edbfb52f8d5d9",
            "89b49a1b5c6d47e9b551f0f5167202ad",
            "10b9635c10d64b62b687605468f2b585",
            "7b37daf40186483aa6d599cbb7786039",
            "6d458f0ccb18497aa0b36b900e5b8668",
            "9dee52b1c1e44838b3d825eea61abb8d",
            "21845092830a4ac595c7870815add762",
            "acb54dbde24c4d7582ad8a24f405a145",
            "2182c500b2424b889eca3fd591aef191",
            "90345df3477546ae9014e4660e7b32e0",
            "ead1119294614bf38f54bce9fc308cb3",
            "998b82bd5ee2471793101b0f3c8bf844",
            "91bbf950c566468ea869563a7c3ed5e9",
            "e657c1dffbf14abb95f3eedcc39b2627",
            "07004af08e0a49e28b77d7b7b358ea1f",
            "02fe33f2313e496283ba708bfbec2326",
            "48a7f75cb18a431e88ff65a3ecf78f8c",
            "d9d43cfe4e0e42598690ca3218c70724",
            "3228326c8463455da48bcdc8d108ab43",
            "e87b2ba1c31341de8de69bc9cab7ef8e",
            "d726b971f2ee458a90808b14cad84885",
            "d00f5aa85a5b4bb2a3fd88df0676bad1",
            "adc1e819a05841849a2999ae81cb5b69",
            "7e6d3ea89fe74f18b371525b6b78bb6e",
            "977adc555cbc44b8a29d8659967cf40f",
            "1270683fbffd4958ba886c4205c1dd9d",
            "efd70d7da0dd4e5c926cca468c4957fb",
            "f7143ec6cc404eb39505518c1f6cc205",
            "44b7684300a044f7a668e77a980bf25d",
            "d1365e6b41ed45b5b1481765cad238af",
            "911dd40eab7041ef91842092df889a08",
            "6446e49aac6c4df394780d5d8b1a298d",
            "56732a7d358c43a7a8686cfaf53a0580",
            "41a7f6bd53c24261970cb0d021534e06",
            "539c685675c94eb4bfb324b2e90e3523",
            "226ccb5e9cdc4456908f38e5cf807f13",
            "5a9c2aaa7b234e739e3e22c0d545b8f9",
            "34b48e2ff22e4e4285b3be686fbd9047",
            "c80caf5b60a345f28b8a6d464493a048",
            "5de1ebf3eedb48f48f96679990b79e60",
            "e8b2e9ac5d1d4dbd997ba7b1fba5f943",
            "1374c75408dd474995523f0c2af08c81",
            "99883c4493544b209bf0fb3cb4e16fbe",
            "d443427bfba24d5aaa3f8fdbb5fae6be",
            "5da305de47b44e5db677c53ec8321e1c",
            "3678af294a4542f488eb6c9c3d24a05c",
            "3a82c2d362f8473f851617f16670f6e0",
            "b04b57eb26174fa6897fb338d2c1f4b0",
            "e6c379b6c07e46319cace3158a4df566",
            "e2051ec00a7b4b1cb284c22304ba4eb5",
            "baaa5938460c471790320def52ff7046",
            "df60829d95954705b0183567a27b094f",
            "ecab029f970040b38a9df40415991e0b",
            "a3fe583686c844a7ae6e866179874f5c",
            "64c36d5418ab4f11a29b906cfa76e5c9",
            "25d2d44384f04c2dbf4ae0c04d65946d",
            "086b9f4cfbd14617b44629b7390e0d12",
            "59a109ac25a54b39ad75a791f18e1ecd",
            "933e6d06000048f28907c150e531274d",
            "f622d1a5f5194268b8bbd59a6feb0600",
            "b20a9308445143b7b00b9e39f816b859",
            "5d7e966bf68d48d085944c3e07de01f6",
            "525466843ea54d338804e4ef1b8eb80a",
            "c0f4ff87738f47778c7b81c6e167cb24",
            "964e2061cc6b48bbb29a543c6c0a7d8f",
            "ccf7275f305048ee979cf75a5c313ed9",
            "0e37a689bf554f38a7446953756745a9",
            "cb0856f6164f4930934173e4aed4219c",
            "6a59a9f758344f3e85e34d3306ef582e",
            "457f9466811d4b2a98e8314d9a0ff2d2",
            "d5479ef2f4b84743ba764d1d6ba6a105",
            "233d6333408b43b3ac06e40069159bf6",
            "0e1abbc5758e4ab1b549e09d7e395836",
            "2f85c1ebbaa2416b9c74e8949074ccbc",
            "60ad66ff6c8c4827a86ea7ed181bdf2d",
            "0a4b9c9708794323863bd00bd33bd022",
            "6710561ae96c443da660980b92b07dba",
            "52ab269a377940ff89dedbf9bdc6ffd2",
            "13d33ab4757540c881669e85696f6578",
            "371f345f8d4645b48d4207e7fceb49ea",
            "9773cfd0751b4207be7ec9669245d0f2",
            "3e88b4f02d5c4507b38e51048161ef00",
            "d09ee669a091476dad13c594b1431f05",
            "865fb5eef9074e0781dcf7c789461be1",
            "ced668d6041d46da82098a53317efceb",
            "95f5d2e5732d4d3c89c4c1306936ee1d",
            "ee98c2d0f597468ca4bd3e0f48de8760",
            "0171e8ef1da14e218dc7203d20a6ce9c",
            "39cb322c3ce8461a88399006ac96f84a",
            "cc25d86900284113bf29f82354081908",
            "c93cd689f8234f20825d90d4de1ef67e",
            "43927df504ca40549ec3440aa070e850",
            "3696a4a3243640b8b36f138f61125caf",
            "3f3920621a1c47bbb9cb1c10d82346d0",
            "78cedeea2f664453b0176845512a2293",
            "74ed4c3b6d454c008faaa895c99bd6cc",
            "6073a40636ca403b8f2660dafa924d87",
            "b12430c8e9724cbdbb071494749ccd02",
            "0484f8990eaf49f0a4cad556a59a68be",
            "491e6f7698734eed91da4bee83c68b00",
            "c83c74feeb8f4fa8a8e5c58e0247d958",
            "00473a69288d45ddb03c670a5d8c1c0d",
            "e7a7f8f9c15a49989d4e42e8ce18ce67",
            "d12a0630f2cc4405a375ee9646f3b9da",
            "3b19b0aceb0c4bc78c966d73bdc8d13a",
            "10a7a0da8f854ab2ab2cec22d45b39d0",
            "e7a0a27e48b9493599911148dc750c4e",
            "c7bde8fd2d6e44658b21a940e003efbd",
            "e53d4b8ba6ea4e02ae57f5bf4282d665",
            "14b6577b0f5f4a1e95ce6d0bfd0ced5e"
          ]
        },
        "id": "Um4q4Q30nA23",
        "outputId": "d83e778b-b6e4-460e-86d4-108fb4a5b4e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7296ecc159d24531964edbfb52f8d5d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "998b82bd5ee2471793101b0f3c8bf844"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adc1e819a05841849a2999ae81cb5b69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41a7f6bd53c24261970cb0d021534e06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5da305de47b44e5db677c53ec8321e1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25d2d44384f04c2dbf4ae0c04d65946d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e37a689bf554f38a7446953756745a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52ab269a377940ff89dedbf9bdc6ffd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39cb322c3ce8461a88399006ac96f84a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "491e6f7698734eed91da4bee83c68b00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 7: PREPARAÇÃO DO BANCO DE DADOS VETORIAL\n",
        "# =============================================================================\n",
        "# Configuração do ChromaDB\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "# Criação da coleção\n",
        "collection_name = \"essays_feedback\"\n",
        "\n",
        "try:\n",
        "  collection = chroma_client.get_collection(name=collection_name)\n",
        "  print(f\"Collection '{collection_name}' already exists.\")\n",
        "except:\n",
        "  collection = chroma_client.create_collection(name=collection_name)\n",
        "  print(f\"Collection '{collection_name}' created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LakXAxCNnPVP",
        "outputId": "1cf90c4c-5402-4d97-e2e5-865c0a1bad8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collection 'essays_feedback' created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para gerar embeddings e adicionar ao ChromaDB\n",
        "def add_to_chroma(documents: list[str], metadatas: list[dict], ids: list[str]):\n",
        "  \"\"\"\n",
        "  Adiciona documentos ao ChromaDB.\n",
        "\n",
        "  Args:\n",
        "    documents (list[str]): Lista dos documentos para adicionar.\n",
        "    metadatas (list[dict]): Lista dos metadados associados aos documentos.\n",
        "    ids (list[str]): Lista dos IDs associados aos documentos.\n",
        "\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  # Geração dos embeddings\n",
        "  embeddings = embedding_model.encode(documents, batch_size=32, show_progress_bar=True).tolist()\n",
        "\n",
        "  # Adição dos embeddings ao ChromaDB\n",
        "  print(f\"\\nAdding {len(documents)} documents to ChromaDB...\")\n",
        "  collection.add(\n",
        "      embeddings=embeddings,\n",
        "      documents=documents,\n",
        "      metadatas=metadatas,\n",
        "      ids=ids\n",
        "  )\n",
        "  print(f\"{len(documents)} documents added to collection '{collection_name}'\")\n",
        "\n",
        "# Preparação dos dados\n",
        "docs_to_index = df_essays['COMMENTS'].tolist()\n",
        "metadatas_to_index = [{\"type\": \"essay_comment\"}] * len(docs_to_index)\n",
        "ids_to_index = [f\"essay_comment_{i}\" for i in range(len(df_essays))]\n",
        "\n",
        "add_to_chroma(docs_to_index, metadatas_to_index, ids_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "389fd87833ac4536b0261c75eab2df04",
            "1960b71fd0c04e34809389bfea52ac55",
            "3257ce25b9524a289d81f231290a8a62",
            "21ca1926fb244aa0bc4c92244924d6d6",
            "25d608410bf64f17b1817e6adf4b9cb3",
            "8235a1dce9e346f682f4e3a4c929c3fe",
            "2eb24cf1d9f0463887a0b05177a68af9",
            "fe9de18ddbc54e78be4cad7750742828",
            "5b2664081a36457e947458cd69fc72ec",
            "8b5e4a3fb72e4ffdb5367b8e6d14d9e6",
            "ae2ce5189ae1467697f62424d87aa81e"
          ]
        },
        "id": "-JfXb9yYnY7-",
        "outputId": "36e8cd57-3342-4f44-cd61-ef708decb9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/68 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "389fd87833ac4536b0261c75eab2df04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Adding 2162 documents to ChromaDB...\n",
            "2162 documents added to collection 'essays_feedback'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para buscar informações relevantes\n",
        "def search_chroma(query_text: str, n_results: int) -> list[str]:\n",
        "  \"\"\"\n",
        "  Busca os documentos mais relevantes.\n",
        "\n",
        "  Args:\n",
        "    query_text (str): Texto de consulta.\n",
        "    n_results (int): Número de resultados a serem retornados.\n",
        "\n",
        "  Returns:\n",
        "    list[str]: Lista dos documentos mais relevantes.\n",
        "  \"\"\"\n",
        "  # Geração do embedding da consulta\n",
        "  query_embedding = embedding_model.encode(query_text).tolist()\n",
        "\n",
        "  # Consulta ao ChromaDB para encontrar documentos mais relevantes com base na similaridade dos embeddings\n",
        "  results = collection.query(\n",
        "      query_embeddings=[query_embedding],\n",
        "      n_results=n_results,\n",
        "      include=['documents', 'metadatas']\n",
        "  )\n",
        "\n",
        "  relevant_docs = []\n",
        "  if results and results.get('documents') and results['documents'][0]:\n",
        "    for doc, meta in zip(results['documents'][0], results.get('metadatas', [{}])[0]):\n",
        "      relevant_docs.append({\"text\": doc, \"metadata\": meta})\n",
        "\n",
        "  return relevant_docs"
      ],
      "metadata": {
        "id": "F_L2Lsnynkb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 8: PREPARAÇÃO DOS DADOS\n",
        "# =============================================================================\n",
        "# Template do prompt para treinamento\n",
        "TRAINING_IN_FMT = \"\"\"Você é um assistente especializado em dar feedback para redações do ENEM.\n",
        "\n",
        "Tema: {tema}\n",
        "\n",
        "Redação:\n",
        "{redacao}\n",
        "\n",
        "Feedback:\n",
        "\"\"\"\n",
        "\n",
        "# Template do prompt para inferência\n",
        "RAG_IN_FMT = \"\"\"Você é um assistente especializado em dar feedback para redações do ENEM.\n",
        "Utilize os seguintes contextos para auxiliar na geração do feedback, focando em gramática, coesão, coerência e argumentação.\n",
        "Seja construtivo e objetivo.\n",
        "\n",
        "{context}\n",
        "\n",
        "Tema: {tema}\n",
        "\n",
        "Redação:\n",
        "{redacao}\n",
        "\n",
        "Feedback:\n",
        "\"\"\"\n",
        "\n",
        "# Conversão do DataFrame para um Hugging Face Dataset\n",
        "ds = Dataset.from_pandas(df_essays)\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc-PhS8Nno6O",
        "outputId": "406e9af9-0ff1-4b9d-d1c9-da7ef7acc008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['THEME', 'ESSAY', 'COMMENTS', '__index_level_0__'],\n",
              "    num_rows: 2162\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 9: TOKENIZAÇÃO\n",
        "# =============================================================================\n",
        "# Tamanho máximo da sequência\n",
        "MAX_LEN = 512\n",
        "\n",
        "# Função de tokenização que processa cada exemplo\n",
        "def tok_example(example):\n",
        "  \"\"\"\n",
        "  Tokeniza um exemplo de dados.\n",
        "\n",
        "  Args:\n",
        "    example (dict): Exemplo de dados.\n",
        "\n",
        "  Returns:\n",
        "    dict: Exemplo de dados tokenizados.\n",
        "  \"\"\"\n",
        "  prompt = TRAINING_IN_FMT.format(tema=example['THEME'], redacao=example['ESSAY'])\n",
        "\n",
        "  tp = tok(prompt, add_special_tokens=False)\n",
        "  tr = tok(example['COMMENTS'] + tok.eos_token, add_special_tokens=False)\n",
        "\n",
        "  ids = (tp['input_ids'] + tr['input_ids'])[:MAX_LEN]\n",
        "  att = [1] * len(ids)\n",
        "  lab = ([-100]*len(tp[\"input_ids\"]) + tr[\"input_ids\"])[:MAX_LEN]\n",
        "\n",
        "  return {\"input_ids\": ids, \"attention_mask\": att, \"labels\": lab}\n",
        "\n",
        "train_ds = ds.map(tok_example, remove_columns=ds.column_names)\n",
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "f1cb804ac7f8429ebe07705836ca1347",
            "c4ab1d479e0d4632932685191c90fa7e",
            "da7ccb0eb5694553b457123185db5832",
            "93f7d46e3499402091bd81b1c0bd7f28",
            "16e024e5e3b145f7a1aa1107af1c3d20",
            "5658d45218af4f27abbda903457c222b",
            "e7b91c04840a4fa0861409faece0b11c",
            "2b61206058c54472bb319c443ac4917a",
            "7a77329529d846cca45172e19ff366e8",
            "a51bb99bc66c498e85c603688341b842",
            "94e8137faa684e83ae217b4befc0fef4"
          ]
        },
        "id": "MlOK_Qw-n7vH",
        "outputId": "321072a4-5e44-40e9-ce49-a63ff0cc098a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2162 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1cb804ac7f8429ebe07705836ca1347"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 2162\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 10: BATCH\n",
        "# =============================================================================\n",
        "def collate(batch):\n",
        "  \"\"\"\n",
        "  Função de processamento de lote.\n",
        "\n",
        "  Args:\n",
        "    batch (list): Lista de exemplos de dados.\n",
        "\n",
        "  Returns:\n",
        "    dict: Exemplo de dados processados.\n",
        "  \"\"\"\n",
        "\n",
        "  # Função auxiliar para a organização das redações\n",
        "  def pad_list(lst, pad_value):\n",
        "    maxlen = max(len(x) for x in lst)\n",
        "\n",
        "    out = []\n",
        "    for x in lst:\n",
        "      t = torch.tensor(x, dtype=torch.long)\n",
        "\n",
        "      if t.size(0) < maxlen:\n",
        "        t = torch.nn.functional.pad(t, (0, maxlen - t.size(0)), value=pad_value)\n",
        "      out.append(t)\n",
        "\n",
        "    return torch.stack(out)\n",
        "\n",
        "  ids = [b[\"input_ids\"] for b in batch]\n",
        "  att = [b[\"attention_mask\"] for b in batch]\n",
        "  lab = [b[\"labels\"] for b in batch]\n",
        "\n",
        "  return{\n",
        "    \"input_ids\": pad_list(ids, tok.pad_token_id),\n",
        "    \"attention_mask\": pad_list(att, 0),\n",
        "    \"labels\": pad_list(lab, -100)\n",
        "  }"
      ],
      "metadata": {
        "id": "HQ5ZGqFgoFrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 11: CONFIGURAÇÃO DO TREINAMENTO\n",
        "# =============================================================================\n",
        "# Criação de um batch com 12 exemplos para ajudar no aprendizado do modelo\n",
        "# de uma maneira mais estável com per_device_train_batch_size=4 e\n",
        "# gradient_accumulation_steps=3.\n",
        "\n",
        "# Aumento gradual da velocidade de aprendizado no início e, depois, diminuição\n",
        "# suave com lr_scheduler_type=\"cosine\" e warmup_steps=50.\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./essay\",\n",
        "    max_steps=300, # Controle da duração do treino\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=3,\n",
        "    learning_rate=2e-5, # Velocidade de aprendizado mais segura\n",
        "    bf16=True, # Treino mais rápido, mas com um menor uso da memória\n",
        "    group_by_length=True, # Organização dos exemplos de redações por tamanho\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_steps=50,\n",
        "    logging_steps=50,\n",
        "    save_steps=100,\n",
        "    report_to=\"none\",\n",
        "    optim=\"paged_adamw_32bit\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, args=args, train_dataset=train_ds, data_collator=collate)\n",
        "trainer.model.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c2pxTIYoNRV",
        "outputId": "8073e66f-d4c4-4e53-da9a-dae41f1540f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2Config {\n",
              "  \"architectures\": [\n",
              "    \"Qwen2ForCausalLM\"\n",
              "  ],\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 151643,\n",
              "  \"dtype\": \"bfloat16\",\n",
              "  \"eos_token_id\": 151645,\n",
              "  \"hidden_act\": \"silu\",\n",
              "  \"hidden_size\": 896,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 4864,\n",
              "  \"layer_types\": [\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\",\n",
              "    \"full_attention\"\n",
              "  ],\n",
              "  \"max_position_embeddings\": 32768,\n",
              "  \"max_window_layers\": 21,\n",
              "  \"model_type\": \"qwen2\",\n",
              "  \"num_attention_heads\": 14,\n",
              "  \"num_hidden_layers\": 24,\n",
              "  \"num_key_value_heads\": 2,\n",
              "  \"rms_norm_eps\": 1e-06,\n",
              "  \"rope_scaling\": null,\n",
              "  \"rope_theta\": 1000000.0,\n",
              "  \"sliding_window\": null,\n",
              "  \"tie_word_embeddings\": true,\n",
              "  \"transformers_version\": \"4.57.3\",\n",
              "  \"use_cache\": false,\n",
              "  \"use_sliding_window\": false,\n",
              "  \"vocab_size\": 151936\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 12: TREINAMENTO\n",
        "# =============================================================================\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "KAO2OlAFpAvF",
        "outputId": "af0c531f-0ec0-4ac7-d59a-973c294c47b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/300 11:49 < 23:45, 0.14 it/s, Epoch 0.55/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.784600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 13: GERAÇÃO\n",
        "# =============================================================================\n",
        "# Antes da busca, a redação é truncada para prevenção de erros de dimensão no\n",
        "# modelo de embedding, focando no início/corpo do texto, o que garante que o\n",
        "# contexto recuperado seja semanticamente relevante.\n",
        "def generate(instr):\n",
        "  \"\"\"\n",
        "  Função para gerar feedback a partir de uma redação.\n",
        "\n",
        "  Args:\n",
        "    instr (dict): Dicionário contendo o tema e a redação.\n",
        "\n",
        "  Returns:\n",
        "    generated_text (str): Feedback gerado.\n",
        "  \"\"\"\n",
        "  # Busca pelos trechos de texto mais relevantes relacionados à redação em questão\n",
        "  max_query_tokens = 256 # Limite para a consulta de busca\n",
        "  tokens_obj = tok(instr['ESSAY'], max_length=max_query_tokens, truncation=True, return_tensors=\"pt\", add_special_tokens=False)\n",
        "  search_query = tok.decode(tokens_obj['input_ids'][0], skip_special_tokens=True)\n",
        "  relevant_contexts = search_chroma(search_query, 3) # 3 trechos mais relevantes\n",
        "\n",
        "  instr_context = \"\\n\".join([doc[\"text\"] for doc in relevant_contexts])\n",
        "  prompt = RAG_IN_FMT.format(context=instr_context, tema=instr['THEME'], redacao=instr['ESSAY'])\n",
        "\n",
        "  x = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "  # Geração da resposta\n",
        "  with torch.no_grad():\n",
        "    y = model.generate(\n",
        "        **x,\n",
        "        max_new_tokens=600,\n",
        "        do_sample=True,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7,\n",
        "        eos_token_id=tok.eos_token_id,\n",
        "        pad_token_id=tok.pad_token_id,\n",
        "        no_repeat_ngram_size=5 # Força a diversidade vocabular, impedindo loops de frase comuns\n",
        "    )\n",
        "\n",
        "    # Processamento da saída\n",
        "    input_len = x[\"input_ids\"].shape[1]\n",
        "    generated_tokens = y[0][input_len:]\n",
        "    generated_text = tok.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "    print(\"=\"*40)\n",
        "    print(f\"TEMA: {instr['THEME']}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"FEEDBACK:\\n\")\n",
        "    print(generated_text)\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "RdCZvClWpJQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste\n",
        "example = df_essays.iloc[1]\n",
        "generated_text = generate(example)"
      ],
      "metadata": {
        "id": "LeNKssV1pgce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PASSO 14: AVALIAÇÃO\n",
        "# =============================================================================\n",
        "rouge = load(\"rouge\")\n",
        "\n",
        "def evaluate(reference_text, generated_text, lang=\"pt\"):\n",
        "  \"\"\"\n",
        "  Função para avaliar a saída do modelo.\n",
        "\n",
        "  Args:\n",
        "    reference_text (str): Texto de referência.\n",
        "    generated_text (str): Texto gerado.\n",
        "    lang (str): Idioma dos textos.\n",
        "\n",
        "  Returns:\n",
        "    rouge_results (dict): Resultados do ROUGE.\n",
        "    bert_precision (torch.Tensor): Precisão do BERT.\n",
        "    bert_recall (torch.Tensor): Revocação do BERT.\n",
        "    bert_f1 (torch.Tensor): F1\n",
        "    bleu_score (float): BLEU.\n",
        "  \"\"\"\n",
        "  references = [reference_text]\n",
        "  predictions = [generated_text]\n",
        "\n",
        "  # ROUGE\n",
        "  rouge_results = rouge.compute(predictions=predictions, references=references)\n",
        "  # BERTScore\n",
        "  bert_precision, bert_recall, bert_f1 = score(references, predictions, lang=lang, verbose=False)\n",
        "  # BLEU\n",
        "  bleu_score = sentence_bleu(references, generated_text)\n",
        "\n",
        "  return rouge_results, bert_precision, bert_recall, bert_f1, bleu_score\n",
        "\n",
        "rouge_results, bert_precision, bert_recall, bert_f1, bleu_score = evaluate(example['COMMENTS'], generated_text)\n",
        "\n",
        "print(\"=\"*40)\n",
        "print(\"   AVALIAÇÃO\")\n",
        "print(\"ROUGE Scores:\")\n",
        "print(f\" ROUGE-1: {rouge_results['rouge1']:.3f}\")\n",
        "print(f\" ROUGE-2: {rouge_results['rouge2']:.3f}\")\n",
        "print(f\" ROUGE-L: {rouge_results['rougeL']:.3f}\")\n",
        "print(\"-\"*40)\n",
        "print(\"BERT Scores:\")\n",
        "print(f\" Precision: {bert_precision.mean().item():.3f}\")\n",
        "print(f\" Recall:    {bert_recall.mean().item():.3f}\")\n",
        "print(f\" F1:        {bert_f1.mean().item():.3f}\")\n",
        "print(\"-\"*40)\n",
        "print(f\"BLEU Score: {bleu_score:.3f}\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "id": "wPEBmCqepjdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***(ALTERAR!)***\n",
        "\n",
        "Os resultados indicam um modelo que aprendeu o \"conceito\" do feedback, mas manteve liberdade criativa na escrita:\n",
        "\n",
        "* Sucesso Semântico (BERTScore ~0.74): Este é o indicador mais crítico. Um F1 de 0.75 é considerado alto para tarefas de geração aberta. Isso prova que, mesmo usando palavras diferentes, o modelo preservou a intenção e o significado da referência. O Recall (0.747) superior à Precision sugere que o modelo é exaustivo: ele cobre quase todos os pontos da referência, raramente omitindo críticas importantes.\n",
        "\n",
        "* Comportamento Abstrativo (ROUGE Gap): A queda acentuada entre ROUGE-1 (51% de overlap de palavras) e ROUGE-L (16% de estrutura frasal) é positiva neste contexto. Ela confirma que o modelo não está memorizando (overfitting) frases inteiras. Ele absorveu o vocabulário técnico (garantindo o ROUGE-1 e o BLEU alto de 0.61), mas constrói sentenças novas sintaticamente distintas da referência."
      ],
      "metadata": {
        "id": "mO4acPKCpvym"
      }
    }
  ]
}